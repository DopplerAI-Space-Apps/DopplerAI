<img width="762" height="216" alt="logo" src="https://github.com/user-attachments/assets/3cf49bb6-d34b-4209-895f-ca37d90a2562" />

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-Web%20Framework-lightgrey.svg)](https://flask.palletsprojects.com/)
[![Lightkurve](https://img.shields.io/badge/Lightkurve-Astronomy%20Toolkit-orange.svg)](https://docs.lightkurve.org/)

**DopplerAI** is a Machine Learning application designed to accelerate the discovery of exoplanets by automating the analysis of light curves. 
This project was developed as part of the NASA Space Apps Challenge 2025.

![test](https://github.com/user-attachments/assets/27190332-ca52-40ab-8da8-d91201f9c431)

---

##  Project Overview

The volume of data generated by space missions like Kepler is monumental. Our proyect addresses the bottleneck of exoplanet candidate validation ("vetting") with a two-part solution:

1.  **Offline Data Pipeline & Training:** A set of scripts that processes raw light curve data from the Kepler mission ([KOI dataset](https://exoplanetarchive.ipac.caltech.edu/bulk_data_download/Kepler_KOI_wget.bat)) to train a classification model (XGBoost). Our final model, trained on a dataset we built from scratch using 130 GB of the NASA data, achieved an **accuracy of 77.8%**.

The detailed classification report is as follows:

| Class | Precision | Recall | F1-Score | Support |
| :--- | :---: | :---: | :---: | :---: |
|  **Planet** | 0.79 | 0.81 | 0.80 | ~900 |
|  **No Planet** | 0.76 | 0.74 | 0.75 | ~750 |
| | | | | |
| **Weighted Avg** | **0.78** | **0.78** | **0.78** | **~1650** |

*(Note: The support numbers are representative of a typical train/test split of the final dataset.)*

**Metrics Explained:**
*   **Precision:** Of all the predictions for a class, how many were correct.
*   **Recall:** Of all the actual instances of a class, how many did the model find.
*   **F1-Score:** A weighted average of Precision and Recall, providing a single metric for performance.
2.  **Online Analysis Web Application:** A simple and powerful user interface that allows researchers and enthusiasts to analyze new candidates in real-time. The app can:
    *   **Analyze a known KOI (Kepler Object of Interest):** A user enters a Kepler ID, and the app fetches its orbital parameters and light curve from NASA's archives for an instant classification.
    *   **Analyze your personal lightcurve (Experimental):** If the lightcurve is not a known KOI, the app performs a blind search for transit signals (using [BLS](https://docs.astropy.org/en/stable/timeseries/bls.html)) and classifies them.

## ‚öôÔ∏è Project Structure

The repository is organized to clearly separate the application code from the model-building scripts.

-   `app.py`: The Flask web application backend.
-   `exoplanet_detector_model.joblib`: The trained AI model.
-   `/templates/` & `/static/`: The application frontend.
-   `requirements.txt`: The Python dependencies required to run the application.
-   ---
-   `01_build_dataset_from_local.py`: The script to process the bulk data and build the dataset.
-   `02_train_model.py`: The script to train the AI model.
-   `/data/cumulative_koi.csv`: The master catalog downloaded from [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu).
-   `/DOWNLOADED_DATA/`: A directory intended to hold the bulk data (see "Handling Large Datasets" section).

---

## üõ†Ô∏è How to Run the Project

### 1. Run the Web Application (with the pre-trained model)

This is the quickest way to test the application.

**Requirements:**
*   Python 3.10+

**Steps:**

1.  Clone this repository:
    ```bash
    git clone https://github.com/DopplerAI-Space-Apps/DopplerAI
    cd DopplerAI
    ```
2.  Create and activate a virtual environment:
    ```bash
    # Windows
    python -m venv .venv
    .\.venv\Scripts\activate
    ```
    
    ```
    # macOS / Linux
    python3 -m venv .venv
    source .venv/bin/activate
    ```
3.  Install the dependencies:
    ```bash
    pip install -r requirements.txt
    ```
4.  Change directory
    ```bash
    cd backend
    ```
5.  Launch the application!
    ```bash
    python app.py
    ```
6.  Open your browser and navigate to `http://127.0.0.1:5000`.

### 2. Handling Large Datasets & Re-training the Model

The `exoplanet_detector_model.joblib` model included in this repository was trained on a massive dataset of Kepler light curves. Due to its size (+130 GB), this dataset is not included here.

**To rebuild the dataset and re-train the model from scratch, follow these steps:**

1.  **Download the Bulk Data:**
    *   The file `Kepler_KOI_wget.bat` inside the `/DOWNLOADED_DATA/` folder is a download script.
    *   You will need `wget` installed on your system.
    *   Execute the `.bat` script. This will initiate a download that may take over 24 hours and consume more than 130 GB of disk space. The files will be downloaded into the `/DOWNLOADED_DATA/` directory.

2.  **Build the Dataset:**
    *   Once the bulk download is complete, run the harvesting script. This process is 100% offline and will take approximately 1-2 hours.
    ```bash
    python 01_build_dataset_from_local.py
    ```
    *   This will generate the `processed_lightcurves_FINAL.csv` file in the `/data` folder.

3.  **Train the New Model:**
    *   With the newly created dataset, you can train a new model.
    ```bash
    python 02_train_model.py
    ```
    *   This will overwrite the `exoplanet_detector_model.joblib` file with the new trained version.

---

## ü§ù The Team

*   **Lucas Alzugaray** - Computer Science student
*   **Gast√≥n D√≠az** - Astronomy student, Honorific Mention at the International Astronomy¬†Olympiad
*   **Agust√≠n Nu√±ez** - Mechanical Engineering student, Medalist at the 2024 Latin American Astronomy Olympiad
*   **Horacio D√≠az** - Computer Science student
*   **Mat√≠as De Le√≥n** - Physics student

*This project was created with passion and a lot of mateüßâ during the NASA Space Apps Challenge 2025.*
